/*
All material copyright ESRI, All Rights Reserved, unless otherwise specified.
See https://js.arcgis.com/4.23/esri/copyright.txt for details.
*/
import{ShaderOutput as e}from"../views/3d/webgl-engine/core/shaderLibrary/ShaderOutputOptions.js";import{Slice as i}from"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js";import{OutputHighlight as o}from"../views/3d/webgl-engine/core/shaderLibrary/output/OutputHighlight.glsl.js";import{RgbaFloatEncoding as t}from"../views/3d/webgl-engine/core/shaderLibrary/util/RgbaFloatEncoding.glsl.js";import{glsl as r}from"../views/3d/webgl-engine/core/shaderModules/interfaces.js";import{ShaderBuilder as a}from"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js";import{VertexAttribute as n}from"../views/3d/webgl-engine/lib/VertexAttribute.js";function s(s){const c=new a,d=s.output===e.Color,l=s.output===e.Depth,p=s.output===e.Highlight;return c.extensions.add("GL_OES_standard_derivatives"),c.include(i,s),c.attributes.add(n.POSITION,"vec3"),c.attributes.add(n.COLOR,"vec3"),c.vertex.uniforms.add("modelView","mat4").add("proj","mat4").add("screenMinMaxSize","vec2").add("pointScale","vec2").add("clipMin","vec3").add("clipMax","vec3"),l?(c.vertex.uniforms.add("nearFar","vec2"),c.varyings.add("depth","float")):s.output!==e.Highlight&&c.varyings.add("vColor","vec3"),c.vertex.code.add(r`
    void main(void) {
      // Move clipped points outside of clipspace
      if (position.x < clipMin.x || position.y < clipMin.y || position.z < clipMin.z ||
        position.x > clipMax.x || position.y > clipMax.y || position.z > clipMax.z) {
        gl_Position = vec4(0.0,0.0,0.0,2.0);
        gl_PointSize = 0.0;
        return;
      }

      if (rejectBySlice(position)) {
        gl_Position = vec4(0.0,0.0,0.0,2.0);
        gl_PointSize = 0.0;
        return;
      }

      // Position in camera space
      vec4 camera = modelView * vec4(position, 1.0);

      float pointSize = pointScale.x;
      vec4 position = proj * camera;
     ${s.drawScreenSize?r`
      float clampedScreenSize = pointSize;`:r`
      float pointRadius = 0.5 * pointSize;
      vec4 cameraOffset = camera + vec4(0.0, pointRadius, 0.0, 0.0);
      vec4 positionOffset = proj * cameraOffset;
      float radius = abs(positionOffset.y - position.y);
      float viewHeight = pointScale.y;
      // screen diameter = (2 * r / w) * (h / 2)
      float screenPointSize = (radius / position.w) * viewHeight;
      float clampedScreenSize = clamp(screenPointSize, screenMinMaxSize.x, screenMinMaxSize.y);
      // Shift towards camera, to move rendered point out of terrain i.e. to
      // the camera-facing end of the virtual point when considering it as a
      // 3D sphere.
      camera.xyz -= normalize(camera.xyz) * pointRadius * clampedScreenSize / screenPointSize;
      position = proj * camera;`}

     gl_PointSize = clampedScreenSize;
     gl_Position = position;

     ${l?r`depth = (-camera.z - nearFar[0]) / (nearFar[1] - nearFar[0]);`:""}
     ${d?r`vColor = color;`:""}
    }
  `),c.fragment.include(t,s),p&&c.include(o),c.fragment.code.add(r`
    void main(void) {
      vec2 vOffset = gl_PointCoord - vec2(0.5, 0.5);
      float r2 = dot(vOffset, vOffset);

      if (r2 > 0.25) {
        discard;
      }
      ${l?r`gl_FragColor = float2rgba(depth);`:""}
      ${p?r`outputHighlight();`:""}
      ${d?r`gl_FragColor = vec4(vColor, 1.0);`:""}
    }
  `),c}const c=Object.freeze({__proto__:null,build:s});export{c as P,s as b};
